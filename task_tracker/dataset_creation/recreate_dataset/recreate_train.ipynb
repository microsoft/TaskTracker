{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re \n",
    "import os \n",
    "import argparse\n",
    "import wget \n",
    "import random \n",
    "import numpy as np \n",
    "from task_tracker.dataset_creation.task_prompts import generic_task_prompts\n",
    "import copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load indices of data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_indices_pt1 = json.load(open('train_indices_pt1.json'))\n",
    "train_data_indices_pt2 = json.load(open('train_indices_pt2.json'))\n",
    "\n",
    "train_data_indices = train_data_indices_pt1 + train_data_indices_pt2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser(\n",
    "                    prog='Dataset sampling')\n",
    "parser.add_argument('--datasets_dir', default='../datasets', help=\"dir to retrieval datasets files and other resources\") \n",
    "parser.add_argument('--trivia_files', default='trivia_pairs.txt', help='list of probe-answer pairs') \n",
    "parser.add_argument('--saved_injections', default='saved_injections.txt', help=\"path to a file of saved injections generated earlier\") \n",
    "parser.add_argument('--sep_prompt', default='../config_files/sep_prompt.txt', help='none, or a path to a file that contains defense prompt to explain/encourage separation')  \n",
    "\n",
    "\n",
    "args, _ = parser.parse_known_args()\n",
    "\n",
    "\n",
    "#TODO change home of HF to cache any downloaded files \n",
    "os.environ['HF_HOME'] = '/disk3/'\n",
    "os.environ['TRANSFORMERS_CACHE'] = '/disk3/'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download SQuAD and hotpot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets_files = {'SQuAD': {'train': {'name': 'train-v2.0.json', 'url': 'https://rajpurkar.github.io/SQuAD-explorer/dataset/train-v2.0.json'},\n",
    "                            'dev': {'name': 'dev-v2.0.json', 'url': 'https://rajpurkar.github.io/SQuAD-explorer/dataset/dev-v2.0.json'} },\n",
    "\n",
    "                  'hotpot': {'train': {'name': 'hotpot_train_v1.1.json' , 'url': 'http://curtis.ml.cmu.edu/datasets/hotpot/hotpot_train_v1.1.json'},\n",
    "                             'dev': {'name': 'hotpot_dev_fullwiki_v1.json', 'url': 'http://curtis.ml.cmu.edu/datasets/hotpot/hotpot_dev_fullwiki_v1.json'}}\n",
    "                 }\n",
    "\n",
    "def download_datasets(datasets_dir, datasets):\n",
    "    #download the squad and hotpot datasets if they are not downloaded\n",
    "    for dataset in datasets: \n",
    "        os.makedirs(os.path.join(datasets_dir,dataset), exist_ok=True)\n",
    "        for subset in datasets_files[dataset]:  \n",
    "            if not os.path.isfile(os.path.join(datasets_dir,dataset,datasets_files[dataset][subset]['name'])):\n",
    "                wget.download(datasets_files[dataset][subset]['url'], os.path.join(datasets_dir,dataset,datasets_files[dataset][subset]['name']))\n",
    "    return \n",
    "\n",
    "download_datasets(args.datasets_dir, list(datasets_files.keys())) \n",
    "\n",
    "squad_train = json.load(open(os.path.join(args.datasets_dir,'SQuAD',datasets_files['SQuAD']['train']['name'])))\n",
    "squad_dev = json.load(open(os.path.join(args.datasets_dir,'SQuAD',datasets_files['SQuAD']['dev']['name'])))\n",
    "\n",
    "hotpot_train = json.load(open(os.path.join(args.datasets_dir,'hotpot',datasets_files['hotpot']['train']['name'])))\n",
    "hotpot_dev = json.load(open(os.path.join(args.datasets_dir,'hotpot',datasets_files['hotpot']['dev']['name'])))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download Alpaca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Alpaca instructions dataset \n",
    "from datasets import load_dataset\n",
    "alpaca_dataset = load_dataset(\"tatsu-lab/alpaca\")['train'] \n",
    "alpaca_dataset = [item['instruction'] for item in alpaca_dataset if item['input'] == ''] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dependencies from \"datasets\" dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#load the examples of probes and answers \n",
    "f = open(os.path.join(args.datasets_dir,args.trivia_files),\"r\")\n",
    "trivia_pairs = []\n",
    "\n",
    "for pair_index, pair in enumerate(f):\n",
    "    answer = re.findall(\"Answer:.*\", pair)[0]\n",
    "    question = pair.replace(answer,\"\").replace(\"Question:\",\"\").strip()\n",
    "    answer = answer.replace(\"Answer:\",\"\").strip()\n",
    "    trivia_pairs.append(question)\n",
    "\n",
    "\n",
    "def load_sep_prompt():\n",
    "    #Load prompt used to instruct the model how to do separation (if any).\n",
    "    #Could be as simple as saying: consider the following task/question that you should answer. \n",
    "    if args.sep_prompt == 'none': \n",
    "        sep_prompt = ''\n",
    "    else:\n",
    "        with open(os.path.join(args.sep_prompt),\"r\") as f:\n",
    "            sep_prompt = f.read()\n",
    "    return sep_prompt \n",
    "\n",
    "def load_saved_injections():\n",
    "    #Load saved injections generated earlier via GPT-4. \n",
    "    #These are generated trigger sentences that would be used before the payload.  \n",
    "    saved_injections = []\n",
    "    if args.sep_prompt == 'none': \n",
    "        return [] \n",
    "    else:\n",
    "        f = open(os.path.join(args.datasets_dir,args.saved_injections),\"r\")\n",
    "        for injection in f:\n",
    "            saved_injections.append(injection.strip())\n",
    "    return saved_injections \n",
    "        \n",
    "        \n",
    "sep_prompt = load_sep_prompt()\n",
    "saved_injections = load_saved_injections()\n",
    "saved_injections_to_idx = {}\n",
    "for injection_index, injection in enumerate(saved_injections):\n",
    "    saved_injections_to_idx[injection] = injection_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process retrieval files (no need to change)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load datasets in a unified format. \n",
    "#format list of items. each is {'context': <TEXT PARAGRAPH> , 'questions': [{'question':, 'answer'} ... ]}\n",
    "#questions is a list. squad has n questions (usually) for each context. \n",
    "#hotpot is usually one question with many paragraphs. Currently, just concatenate the paragraphs. \n",
    "def process_squad(squad_file):\n",
    "    new_elements = []\n",
    "    for elem in squad_file['data']:\n",
    "        for par in elem['paragraphs']:\n",
    "            paragraph = par['context']\n",
    "            if len(par['qas']) == 0: continue \n",
    "            q_and_a = []\n",
    "            for q in par['qas']:\n",
    "                if len(q['answers']) ==0: continue \n",
    "                q_and_a.append({'question': q['question'],'answer':q['answers'][0]['text']})\n",
    "            if len(q_and_a) != 0: new_elements.append({'context': paragraph, 'questions': q_and_a})\n",
    "    return new_elements\n",
    "\n",
    "def process_hotpot(hotpot_file):\n",
    "    new_elements = []\n",
    "    for elem in hotpot_file:\n",
    "        all_contexts = ''\n",
    "        for context in elem['context']:\n",
    "            all_contexts += 'Article title: '\n",
    "            all_contexts += context[0] + '. '\n",
    "            all_contexts += ' '.join(context[1])\n",
    "        new_elements.append({'context':all_contexts, 'questions': [{'question': elem['question'],'answer':elem['answer']}]})\n",
    "    return new_elements\n",
    "\n",
    "retrieval_datasets = {}\n",
    "retrieval_datasets['SQuAD'] = {'train': process_squad(squad_train), 'dev': process_squad(squad_dev)} \n",
    "retrieval_datasets['hotpot'] = {'train': process_hotpot(hotpot_train), 'dev': process_hotpot(hotpot_dev)} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_secondary_tasks = {'alpaca': alpaca_dataset, 'witness': trivia_pairs, 'generic': generic_task_prompts}\n",
    "\n",
    "def embed_secondary_task(old_item):\n",
    "    item = copy.deepcopy(old_item)\n",
    "    \n",
    "    orig_text = item['orig_text']\n",
    "    secondary_prompt = item['secondary_task_prompt']\n",
    "    trigger = item['trigger']\n",
    "    pos = item['pos']\n",
    "    \n",
    "    embedded_instruction = ''\n",
    "\n",
    "    if trigger and secondary_prompt:\n",
    "        embedded_instruction = trigger + ' ' + secondary_prompt \n",
    "    elif secondary_prompt:\n",
    "        embedded_instruction = secondary_prompt\n",
    "    elif trigger:\n",
    "        embedded_instruction = trigger\n",
    "    annotated_inserted = \" <INSERTED> \" + embedded_instruction + \" </INSERTED>\"\n",
    "        \n",
    "    if pos == 0 and embedded_instruction:\n",
    "        final_text_paragraph = embedded_instruction + ' ' + orig_text\n",
    "        annotated_part1 = \" <PART_1> </PART_1>\"\n",
    "        annotated_part2 = \" <PART_2> \" + orig_text + \" </PART_2>\"\n",
    "    elif pos == -1 and embedded_instruction:\n",
    "        final_text_paragraph = orig_text + ' ' + embedded_instruction \n",
    "        annotated_part1 = \" <PART_1> \" + orig_text + \" </PART_1>\"\n",
    "        annotated_part2 = \" <PART_2> </PART_2>\"\n",
    "    elif embedded_instruction:\n",
    "        final_text_paragraph = \" \".join((orig_text[:pos], embedded_instruction, orig_text[pos:])) \n",
    "        annotated_part1 = \" <PART_1> \" + orig_text[:pos] + \" </PART_1>\"\n",
    "        annotated_part2 = \" <PART_2> \" + orig_text[pos:] + \" </PART_2>\"\n",
    "    annotated_text = annotated_part1 + annotated_inserted + annotated_part2\n",
    "\n",
    "    item['final_text_paragraph'] = final_text_paragraph\n",
    "    item['annotated_paragraph'] = annotated_text\n",
    "    return item \n",
    "    \n",
    "def get_final_paragraph(old_item):\n",
    "    item = copy.deepcopy(old_item)\n",
    "    sep_prompt = item['sep_prompt'] \n",
    "    orig_task_prompt = item['primary_task_prompt']\n",
    "    final_text_paragraph = item['final_text_paragraph']\n",
    "    \n",
    "    final_prompt = sep_prompt + ' ' + orig_task_prompt + ' ' + final_text_paragraph + ' '\n",
    "    item['final_aggregated_prompt'] = final_prompt\n",
    "\n",
    "    return item\n",
    "\n",
    "\n",
    "\n",
    "def fetch_elements_train(old_item):\n",
    "    item = copy.deepcopy(old_item)\n",
    "\n",
    "    dataset_index =  int(item['text_idx'])\n",
    "\n",
    "    orig_text = retrieval_datasets[item['text_data_src']][item['split']][dataset_index]['context']\n",
    "    \n",
    "    question_index = int(item['primary_task_index'])\n",
    "    if item['primary_task_type'] == 'qa':\n",
    "        primary_task_prompt = retrieval_datasets[item['text_data_src']][item['split']][dataset_index]['questions'][question_index]['question']\n",
    "    else:\n",
    "        primary_task_prompt = generic_task_prompts[item['primary_task_type']][question_index]\n",
    "    \n",
    "    if item['secondary_task_type'] == 'alpaca' or item['secondary_task_type'] == 'witness':\n",
    "        corr_secondary_tasks = train_secondary_tasks[item['secondary_task_type']]\n",
    "    else:\n",
    "        corr_secondary_tasks = train_secondary_tasks['generic'][item['secondary_task_type']]\n",
    "    secondary_task_index = str(item['secondary_task_index'])\n",
    "    \n",
    "    if secondary_task_index.isnumeric():\n",
    "        secondary_task_prompt = corr_secondary_tasks[int(secondary_task_index)]\n",
    "        item['trigger'] = saved_injections[int(item['trigger'])]\n",
    "    elif secondary_task_index == '':\n",
    "        secondary_task_prompt = item['trigger']\n",
    "        item['trigger'] = ''\n",
    "    \n",
    "    item['primary_task_prompt'] = primary_task_prompt \n",
    "    item['orig_text'] = orig_text \n",
    "    item['secondary_task_prompt'] = secondary_task_prompt\n",
    "    \n",
    "    \n",
    "    return item \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the training and verify (with hash values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstructed_train = []\n",
    "lost = 0 \n",
    "new_train_item = ''\n",
    "import hashlib\n",
    "\n",
    "hash_object = hashlib.sha256()\n",
    "\n",
    "for train_index, train_item in enumerate(train_data_indices): \n",
    "    new_train_item = copy.deepcopy(train_item)\n",
    "    if not 'final_aggregated_prompt' in train_item: \n",
    "        new_train_item = fetch_elements_train(train_item)\n",
    "\n",
    "        new_train_item = embed_secondary_task(new_train_item)\n",
    "    \n",
    "        new_train_item = get_final_paragraph(new_train_item)\n",
    "        \n",
    "    hash_object.update(new_train_item['final_aggregated_prompt'].encode('utf-8'))\n",
    "    hex_dig = hash_object.hexdigest()\n",
    "        \n",
    "    \n",
    "    assert str(hex_dig) == new_train_item['final_prompt_hash']\n",
    "\n",
    "    reconstructed_train.append(new_train_item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save json file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../dataset_sampled/train_subset.json', 'w') as fout:\n",
    "    json.dump(reconstructed_train, fout)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
