{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "import os \n",
    "import sys\n",
    "import random \n",
    "import numpy as np \n",
    "import torch \n",
    "from torch.utils.data import DataLoader\n",
    "import random\n",
    "current_dir = '/share/projects/TaskTracker/'\n",
    "sys.path.append(current_dir)\n",
    "from training.triplet_probe.models.processing_per_layer import ParallelConvProcessingModel\n",
    "from training.dataset import ActivationsDatasetDynamicPrimaryText\n",
    "from training.utils.constants import TEST_ACTIVATIONS_DIR_PER_MODEL,TEST_CLEAN_FILES_PER_MODEL,TEST_POISONED_FILES_PER_MODEL\n",
    "from trained_probes_paths import TRIPLET_PROBES_PATHS_PER_MODEL\n",
    "\n",
    "MODEL = 'mixtral'\n",
    "TEST_ACTIVATIONS_DIR = TEST_ACTIVATIONS_DIR_PER_MODEL[MODEL]\n",
    "\n",
    "MODEL_OUTPUT_DIR = TRIPLET_PROBES_PATHS_PER_MODEL[MODEL]['path']\n",
    "FILES_CHUNK = 10 \n",
    "BATCH_SIZE = 256 \n",
    "\n",
    "NUM_LAYERS = TRIPLET_PROBES_PATHS_PER_MODEL[MODEL]['num_layers']\n",
    "if MODEL == 'llama3_70b':\n",
    "    FEATURE_DIM = 350 \n",
    "    POOL_FIRST_LAYER = 5\n",
    "else:\n",
    "    FEATURE_DIM = 275\n",
    "    POOL_FIRST_LAYER = 3\n",
    "    \n",
    "\n",
    "LEARNED_EMBEDDINGS_OUTPUT_DIR = os.path.join(MODEL_OUTPUT_DIR, 'learned_embeddings')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ParallelConvProcessingModel(\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       "  (layers_fc): ModuleList(\n",
       "    (0-5): 6 x Sequential(\n",
       "      (0): Conv1d(1, 7, kernel_size=(70,), stride=(1,))\n",
       "      (1): ReLU()\n",
       "      (2): MaxPool1d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n",
       "      (3): Dropout(p=0.5, inplace=False)\n",
       "      (4): Conv1d(7, 10, kernel_size=(50,), stride=(1,))\n",
       "      (5): ReLU()\n",
       "      (6): MaxPool1d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n",
       "      (7): Dropout(p=0.5, inplace=False)\n",
       "      (8): Conv1d(10, 15, kernel_size=(30,), stride=(1,))\n",
       "      (9): ReLU()\n",
       "      (10): MaxPool1d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n",
       "      (11): Dropout(p=0.5, inplace=False)\n",
       "      (12): Conv1d(15, 20, kernel_size=(20,), stride=(1,))\n",
       "      (13): ReLU()\n",
       "      (14): MaxPool1d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n",
       "      (15): Dropout(p=0.5, inplace=False)\n",
       "      (16): Conv1d(20, 25, kernel_size=(5,), stride=(1,))\n",
       "      (17): ReLU()\n",
       "      (18): MaxPool1d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n",
       "      (19): Dropout(p=0.5, inplace=False)\n",
       "      (20): Flatten(start_dim=1, end_dim=-1)\n",
       "    )\n",
       "  )\n",
       "  (final_fc): Linear(in_features=1650, out_features=1024, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ACTIVATIONS_NEW_VARIATIONS_DIR = '/share/projects/jailbreak-activations/data/activations/mistralai-Mixtral-8x7B-Instruct-v0.1/test_more_variations'\n",
    "clean_files  = ['clean_hidden_states_0_1000_20240514_163834_baseline.pt',\n",
    "               'clean_hidden_states_0_1000_20240514_164114_spottlighting_delimiter.pt'\n",
    "               ,'clean_hidden_states_0_1000_20240521_151120_false_positives_wildchat_level1.pt'\n",
    "               ,'clean_hidden_states_0_1000_20240521_151722_false_positives_wildchat_level2.pt'\n",
    "               ,'clean_hidden_states_0_1000_20240521_152326_false_positives_wildchat_level3.pt']\n",
    "\n",
    "poisoned_files = ['poisoned_hidden_states_0_1000_20240513_223212_lie_trigger.pt',\n",
    "                  'poisoned_hidden_states_0_1000_20240513_223740_not_new_trigger.pt',\n",
    "                  'poisoned_hidden_states_0_1000_20240513_223455_no_trigger.pt',\n",
    "                  'poisoned_hidden_states_0_1000_20240513_224025_baseline.pt',\n",
    "                  'poisoned_hidden_states_0_1000_20240513_224310_spottlighting_delimiter.pt',\n",
    "                  'poisoned_hidden_states_0_1000_20240513_224554_translated_trivia.pt']\n",
    "\n",
    "model = ParallelConvProcessingModel(feature_dim=FEATURE_DIM,num_layers=NUM_LAYERS,conv=True,pool_first_layer=POOL_FIRST_LAYER).cuda()\n",
    "model.load_state_dict(torch.load(os.path.join(MODEL_OUTPUT_DIR,'best_model_checkpoint.pth'))['model_state_dict'])\n",
    "model.eval()\n",
    "model.cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time \n",
    "import json \n",
    "def compute_distances(tensor1, tensor2):\n",
    "    distances = torch.norm(tensor1 - tensor2, p=2, dim=-1)\n",
    "    return distances\n",
    "\n",
    "def evaluation(evaluate_files, activations_dir):\n",
    "    all_distances = []\n",
    "    \n",
    "    all_distances_raw = [] \n",
    "    \n",
    "    all_primary_embs = []\n",
    "    all_primary_with_text_embs = []\n",
    "    \n",
    "    batches = 0 \n",
    "    model.eval()\n",
    "    for i in range(0,len(evaluate_files),10):\n",
    "        files = evaluate_files[i:i+10]\n",
    "        dataset = ActivationsDatasetDynamicPrimaryText(files,NUM_LAYERS,activations_dir)\n",
    "        data_loader = DataLoader(dataset, batch_size=256, shuffle=False)\n",
    "        for j, data in enumerate(data_loader):\n",
    "            primary, primary_with_text = data \n",
    "            with torch.no_grad():\n",
    "                with torch.autocast(device_type=\"cuda\",dtype=torch.float32):\n",
    "                    primary_embs = model(primary.cuda())\n",
    "                    primary_with_text_embs = model(primary_with_text.cuda())\n",
    "                \n",
    "                all_distances.extend(compute_distances(primary_embs, primary_with_text_embs).cpu().numpy())\n",
    "                all_distances_raw.extend(compute_distances(primary[:,-1,:], primary_with_text[:,-1,:]).cpu().numpy())\n",
    "                \n",
    "                all_primary_embs.extend(primary_embs.cpu().numpy().tolist())\n",
    "                all_primary_with_text_embs.extend(primary_with_text_embs.cpu().numpy().tolist())\n",
    "\n",
    "            batches += 1 \n",
    "        \n",
    "    return all_distances, all_distances_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_distances_clean, all_distances_clean_raw = evaluation(clean_files,ACTIVATIONS_NEW_VARIATIONS_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_distances_poisoned, all_distances_poisoned_raw = evaluation(poisoned_files, ACTIVATIONS_NEW_VARIATIONS_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distances of clean baseline: 0.557243287563324, with std: 0.19263112545013428\n",
      "distances of clean with spottlighting: 0.5587817430496216, with std: 0.1909443736076355\n",
      "distances of clean with wild chat summarization level1: 1.1579140424728394, with std: 0.3181234896183014\n",
      "distances of clean with wild chat summarization level2: 1.129629373550415, with std: 0.3050914704799652\n",
      "distances of clean with wild chat summarization level3: 0.5492711067199707, with std: 0.20382894575595856\n",
      "#####\n",
      "distances of poisoned with baseline: 1.5718518495559692, with std: 0.16047224402427673\n",
      "distances of poisoned with lie trigger: 1.654449462890625, with std: 0.10929504036903381\n",
      "distances of poisoned with not new trigger: 1.5763373374938965, with std: 0.1275235414505005\n",
      "distances of poisoned with no trigger: 1.3557054996490479, with std: 0.1763605922460556\n",
      "distances of poisoned with spottlighting trigger: 1.4645103216171265, with std: 0.31629806756973267\n",
      "distances of poisoned with translated instructions: 1.2086303234100342, with std: 0.24389784038066864\n"
     ]
    }
   ],
   "source": [
    "### \n",
    "print(f'distances of clean baseline: {np.mean(all_distances_clean[0:500])}, with std: {np.std(all_distances_clean[0:500])}')\n",
    "print(f'distances of clean with spottlighting: {np.mean(all_distances_clean[500:1000])}, with std: {np.std(all_distances_clean[500:1000])}')\n",
    "print(f'distances of clean with wild chat summarization level1: {np.mean(all_distances_clean[1000:2000])}, with std: {np.std(all_distances_clean[1000:2000])}')\n",
    "print(f'distances of clean with wild chat summarization level2: {np.mean(all_distances_clean[2000:3000])}, with std: {np.std(all_distances_clean[2000:3000])}')\n",
    "print(f'distances of clean with wild chat summarization level3: {np.mean(all_distances_clean[3000:])}, with std: {np.std(all_distances_clean[3000:])}')\n",
    "\n",
    "###\n",
    "print('#####')\n",
    "print(f'distances of poisoned with baseline: {np.mean(all_distances_poisoned[1500:2000])}, with std: {np.std(all_distances_poisoned[1500:2000])}' )\n",
    "\n",
    "print(f'distances of poisoned with lie trigger: {np.mean(all_distances_poisoned[0:500])}, with std: {np.std(all_distances_poisoned[0:500])}')\n",
    "print(f'distances of poisoned with not new trigger: {np.mean(all_distances_poisoned[500:1000])}, with std: {np.std(all_distances_poisoned[500:1000])}')\n",
    "print(f'distances of poisoned with no trigger: {np.mean(all_distances_poisoned[1000:1500])}, with std: {np.std(all_distances_poisoned[1000:1500])}')\n",
    "print(f'distances of poisoned with spottlighting trigger: {np.mean(all_distances_poisoned[2000:])}, with std: {np.std(all_distances_poisoned[2000:])}')\n",
    "print(f'distances of poisoned with translated instructions: {np.mean(all_distances_poisoned[2500:])}, with std: {np.std(all_distances_poisoned[2500:])}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
